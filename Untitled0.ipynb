{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNG7GenWMmHwSHgC0ZcIW0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skaurl/HAAFOR-Challenge-2020/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQwVZNuyeIFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aJpQZYmeXlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('/gdrive/My Drive/한양대학교/HAAFOR Challenge 2020/training.csv', encoding='cp949')\n",
        "\n",
        "print(df.dtypes)\n",
        "\n",
        "print('개수 :', len(df))\n",
        "print('최대 길이 :', max(len(l) for l in df['BEFORE_BODY']))\n",
        "print('평균 길이 :', round(sum(map(len, df['BEFORE_BODY'])) / len(df['BEFORE_BODY'])))\n",
        "\n",
        "plt.hist([len(s) for s in df['BEFORE_BODY']], bins=20)\n",
        "plt.xlim(0,1500)\n",
        "plt.xlabel('length of Data')\n",
        "plt.ylabel('number of Data')\n",
        "plt.show()\n",
        "\n",
        "sns.kdeplot([len(s) for s in df['BEFORE_BODY']], shade=True)\n",
        "plt.title('Kernel Density Estimation')\n",
        "plt.show()\n",
        "\n",
        "print('개수 :', len(df))\n",
        "print('최대 길이 :', max(len(l) for l in df['AFTER_BODY']))\n",
        "print('평균 길이 :', round(sum(map(len, df['AFTER_BODY'])) / len(df['AFTER_BODY'])))\n",
        "\n",
        "plt.hist([len(s) for s in df['AFTER_BODY']], bins=20)\n",
        "plt.xlim(0,1500)\n",
        "plt.xlabel('length of Data')\n",
        "plt.ylabel('number of Data')\n",
        "plt.show()\n",
        "\n",
        "sns.kdeplot([len(s) for s in df['AFTER_BODY']], shade=True)\n",
        "plt.title('Kernel Density Estimation')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "442rYEvm6cHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset_path = r'/gdrive/My Drive/한양대학교/HAAFOR Challenge 2020/training.csv'\n",
        "\n",
        "dataset = pd.read_csv(dataset_path, encoding='cp949')\n",
        "dataset = dataset.sample(n=50000, random_state=42)\n",
        "\n",
        "df = pd.DataFrame(columns=['x','y'],index=range(100000))\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "    df.iloc[i,0] = dataset.iloc[i,2]+\" \"+dataset.iloc[i,4]\n",
        "    df.iloc[50000+i,0] = dataset.iloc[i,4]+\" \"+dataset.iloc[i,2]\n",
        "    df.iloc[i,1] = True\n",
        "    df.iloc[50000+i,1] = False\n",
        "\n",
        "df.to_csv('/gdrive/My Drive/한양대학교/HAAFOR Challenge 2020/training_untitled0.csv', encoding='cp949', index=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaeMdPvuVOwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('/gdrive/My Drive/한양대학교/HAAFOR Challenge 2020/training_untitled0.csv', encoding='cp949')\n",
        "\n",
        "print(df.dtypes)\n",
        "\n",
        "print('개수 :', len(df))\n",
        "print('최대 길이 :', max(len(l) for l in df['x']))\n",
        "print('평균 길이 :', round(sum(map(len, df['x'])) / len(df['x'])))\n",
        "\n",
        "plt.hist([len(s) for s in df['x']], bins=20)\n",
        "plt.xlim(0,3000)\n",
        "plt.xlabel('length of Data')\n",
        "plt.ylabel('number of Data')\n",
        "plt.show()\n",
        "\n",
        "sns.kdeplot([len(s) for s in df['x']], shade=True)\n",
        "plt.title('Kernel Density Estimation')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYiU-MxyX8a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Embedding, Reshape, Conv2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder; LE = LabelEncoder()\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def convert_to_ord(data):\n",
        "    try:\n",
        "        return [ord(xx) for xx in data]\n",
        "    except:\n",
        "        print(data)\n",
        "\n",
        "def conv2d_cnn():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=2**16, output_dim=output_dim, input_length=max_len))\n",
        "    model.add(Reshape((max_len, output_dim, 1), input_shape=(max_len, output_dim)))\n",
        "    model.add(Conv2D(filters=filters, kernel_size=(kernel_size, output_dim), strides=(1, 1), padding='valid'))\n",
        "    model.add(GlobalMaxPooling2D())\n",
        "\n",
        "    model.add(Dense(2**6))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation('softmax'))\n",
        "    adam = optimizers.Adam(lr=0.001)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    early_stopping = EarlyStopping(patience=10)\n",
        "    history = model.fit(x_train, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "    return model, history\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    max_len = 3000\n",
        "    output_dim = 200\n",
        "    filters = 400\n",
        "    kernel_size = 5\n",
        "    epochs = 2**7\n",
        "    batch_size = 2**15\n",
        "\n",
        "    dataset_path = r'/gdrive/My Drive/한양대학교/HAAFOR Challenge 2020/training_untitled0.csv'\n",
        "\n",
        "    dataset = pd.read_csv(dataset_path, encoding='cp949')\n",
        "\n",
        "    dataset['x'] = dataset['x'].map(convert_to_ord)\n",
        "    dataset['y'] = LE.fit_transform(dataset['y'])\n",
        "\n",
        "    data = sequence.pad_sequences(dataset['x'], maxlen=max_len)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(data, dataset['y'], test_size=0.1, random_state=42)\n",
        "\n",
        "    print('train_shape : {} / {}'.format(x_train.shape, y_train.shape))\n",
        "    print('test_shape : {} / {}'.format(x_test.shape, y_test.shape))\n",
        "\n",
        "    y_true = copy.deepcopy(y_test)\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)\n",
        "\n",
        "    model, history = conv2d_cnn()\n",
        "\n",
        "    #model.save('/gdrive/My Drive/TEST/model.h5')\n",
        "\n",
        "    scores = model.evaluate(x_test, y_test)\n",
        "    print(scores)\n",
        "    print(\"정확도: %.2f%%\" % (scores[1] * 100))\n",
        "\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    y_true = list(y_true)\n",
        "    y_pred = model.predict_classes(x_test)\n",
        "    y_pred = list(y_pred)\n",
        "\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(pd.crosstab(pd.Series(y_true), pd.Series(y_pred), rownames=['True'], colnames=['Predicted']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}